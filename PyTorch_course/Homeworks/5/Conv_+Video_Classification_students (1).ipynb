{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install git+https://github.com/arogozhnikov/einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0jR6XuUHJ8U",
        "outputId": "28a611f9-e9f9-4866-b0b6-4e659ec2428a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/arogozhnikov/einops\n",
            "  Cloning https://github.com/arogozhnikov/einops to /tmp/pip-req-build-ct7p7ar7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/arogozhnikov/einops /tmp/pip-req-build-ct7p7ar7\n",
            "  Resolved https://github.com/arogozhnikov/einops to commit 5906eb80cebc2e60b4355d4d68f7b5dc26783e45\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separable convolutions"
      ],
      "metadata": {
        "id": "s55ZdNs_dr89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*o3mKhG3nHS-1dWa_plCeFw.png)"
      ],
      "metadata": {
        "id": "GN1Ox7zHeFii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "SdYMgEOTeyX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeparableConv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, bias=False):\n",
        "      \"\"\"\n",
        "      Used data from https://iq.opengenus.org/separable-convolution/\n",
        "      \"\"\"\n",
        "      super(SeparableConv2d, self).__init__()\n",
        "      self.depthwise = nn.Conv2d(\n",
        "          in_channels,\n",
        "          in_channels,\n",
        "          kernel_size,\n",
        "          groups=in_channels\n",
        "      )\n",
        "      self.pointwise = nn.Conv2d(\n",
        "          in_channels,\n",
        "          out_channels,\n",
        "          1\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.depthwise(x)\n",
        "      out = self.pointwise(out)\n",
        "      return out"
      ],
      "metadata": {
        "id": "KOht7Z3XeE34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1 = SeparableConv2d(3, 128, 3)\n",
        "t = torch.rand(1, 3, 7, 7)\n",
        "print(t.shape)\n",
        "print(c1(t).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV9IN-WCgyrt",
        "outputId": "9a064ae8-3bb7-4624-cbc5-93db213010b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 7, 7])\n",
            "torch.Size([1, 128, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R(2+1) conv"
      ],
      "metadata": {
        "id": "yWVO-ilt9Kez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/video/video_classification\n",
        "\n",
        "https://paperswithcode.com/method/2-1-d-convolution"
      ],
      "metadata": {
        "id": "YS4XxtqE7x-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DDI_5xclb7wb1V2vtDzgoAKm2psjd1qb)"
      ],
      "metadata": {
        "id": "DpIH07bvtYlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9u0zA_J97Z2c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class R2_and1_conv(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "\n",
        "    # first step: [c, t, h, w] -> [c, t, h1, w1]\n",
        "    self.conv2d = nn.Conv3d(in_channels, in_channels, (1, kernel_size[1], kernel_size[2]))\n",
        "    print(self.conv2d)\n",
        "    # second step: [c, t, h1, w1] -> [c, t2, h1, w1]\n",
        "    self.conv1d = nn.Conv3d(in_channels, out_channels, (kernel_size[0], 1, 1))\n",
        "    print(self.conv1d)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # [c, t, h, w]\n",
        "    x = self.conv2d(x)\n",
        "    print(x.shape)\n",
        "    x = self.conv1d(x)\n",
        "    print(x.shape)\n",
        "    return x"
      ],
      "metadata": {
        "id": "UL_sMr0n9sUn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [c, t, h, w]\n",
        "x = torch.rand((1, 10, 5, 5))\n",
        "conv3d = nn.Conv3d(in_channels=1, out_channels=1, kernel_size=3)"
      ],
      "metadata": {
        "id": "vBTuhVLV-CqV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_x = conv3d(x)\n",
        "out_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPeBWw0u-rwo",
        "outputId": "4ef6e811-62ad-4d54-c3ad-e01beb2aac32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_x2 = R2_and1_conv(1, 1, [3, 3, 3])(x)\n",
        "out_x2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IY1rj1FAhWu",
        "outputId": "8817b7c5-b657-4ced-af5c-6f70500de55e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv3d(1, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
            "Conv3d(1, 1, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
            "torch.Size([1, 10, 3, 3])\n",
            "torch.Size([1, 8, 3, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-iD_OB5TBw6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Temporal attention"
      ],
      "metadata": {
        "id": "P1OeNvLnJH6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[GLTR](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Global-Local_Temporal_Representations_for_Video_Person_Re-Identification_ICCV_2019_paper.pdf)"
      ],
      "metadata": {
        "id": "_ZkTeAuGL3-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn"
      ],
      "metadata": {
        "id": "joUcJncM4-r3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 100 #10frames\n",
        "d = 20 #inner dim size\n",
        "input_features = torch.rand((d, T))"
      ],
      "metadata": {
        "id": "2rECnjuOL3ih"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GLRT(nn.Module):\n",
        "  def __init__(self, d):\n",
        "    super().__init__()\n",
        "    self.DTP = nn.ModuleList([\n",
        "        nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                d,\n",
        "                d,\n",
        "                3,\n",
        "                dilation=2**k,\n",
        "                padding=(2**(k + 1) + 1) // 2\n",
        "            )\n",
        "        )\n",
        "        for k in range(3)\n",
        "    ])\n",
        "    self.conv1 = nn.Conv1d(d, d, 3, padding=1)\n",
        "    self.conv3 = nn.Conv1d(3*d, 3*d, 3, padding=1)\n",
        "    print(self.DTP)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.pool = nn.AdaptiveAvgPool1d((1,))\n",
        "\n",
        "\n",
        "  def forward(self, f):\n",
        "    F = torch.zeros((3, f.shape[0], f.shape[1]))\n",
        "    for i in range(3):\n",
        "      F[i] = self.DTP[i].forward(f)\n",
        "    print(F.shape)\n",
        "    F = F.reshape((3*f.shape[0],f.shape[1]))\n",
        "    print(F.shape)\n",
        "    B = self.conv3(F)\n",
        "    C = self.conv3(F)\n",
        "    _F = self.conv3(F)\n",
        "    BC = B.t() @ C\n",
        "    print(BC.shape)\n",
        "    BC = self.softmax(BC)\n",
        "    M = _F @ BC\n",
        "    M = self.conv3(M)\n",
        "    print(M.shape)\n",
        "    F += M\n",
        "    print(F.shape)\n",
        "    F = self.pool(F)\n",
        "    return F"
      ],
      "metadata": {
        "id": "SfhKFfQsVmLN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_features.shape)\n",
        "GLRT(d)(input_features).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz3urow5Z-dT",
        "outputId": "bb46b89a-e60a-4be5-bc43-d760f99db09f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 100])\n",
            "ModuleList(\n",
            "  (0): Sequential(\n",
            "    (0): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "  )\n",
            ")\n",
            "torch.Size([3, 20, 100])\n",
            "torch.Size([60, 100])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([60, 100])\n",
            "torch.Size([60, 100])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}
